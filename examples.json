{
    "info": "Text:\nSkip to main content\n\nThis site uses cookies in order to provide you with the best browsing experience. By using this site, you agree to our use of cookies. Learn more about our Cookie Policy.\n\nDecline\nAccept Cookies\nSign In\nSwift Homepage\nSearch for Jobs\nAI/ML Security Engineer page is loaded\nAI/ML Security Engineer\nApply\nlocations\nManassas, United States\nLeiden area, Netherlands\nposted on\nPosted 25 Days Ago\njob requisition id\n2024-14041\n\nABOUT US\n\nWe\u2019re the world\u2019s leading provider of secure financial messaging services, headquartered in Belgium. We are the way the world moves value \u2013 across borders, through cities and overseas. No other organisation can address the scale, precision, pace and trust that this demands, and we\u2019re proud to support the global economy.\u00a0\n\nWe\u2019re unique too. We were established to find a better way for the global financial community to move value \u2013 a reliable, safe and secure approach that the community can trust, completely. We\u2019re always striving to be better and are constantly evolving in an ever-changing landscape, without undermining that trust. Five decades on, our vibrant community reflects the complexity and diversity of the financial ecosystem. We innovate diligently, test exhaustively, then implement fast. In a connected and exciting era, our mission has never been more relevant. Swift now has a presence in 200+ countries and legal territories to serve a community of more than 12,000 banks and financial institutions.\u00a0\u00a0\u00a0\n\nWhat to expect:\nDesign, develop, and implement security frameworks and strategies to protect AI/ML models and their use, and related data, applications and systems from adversarial attacks and other security threats.\nDevelop standards and best practices for a secure use, development, deployment, and operationalization of AI/ML (predictive AI, generative AI and Large Language Models).\nAnalyze potential security risks in AI/ML applications, such as model poisoning, data leakage, and other adversarial machine learning threats, and define mitigations that can be effectively implemented.\nCollaborate with cross-functional teams to ensure AI/ML systems are integrated, deployed or leveraged with robust security practices throughout the development lifecycle of proprietary models, or through the implementation of pre-trained models, AI-based SaaS solutions, ...\nResearch and stay ahead of emerging security threats in AI/ML and propose innovative defense strategies.\nConduct security assessments and robustness testing of AI/ML models, with appropriate tooling, identifying weaknesses and providing recommendations for improvement.\nCollaborate with internal teams to ensure compliance with relevant regulations, standards, and security frameworks in AI/ML-related initiatives.\nProvide guidance and act as centre of expertise for business, technical, legal, privacy and risk teams on assessing risks and implementing controls for AI/ML projects.\nEffectively communicate complex AI/ML security assessments, risks, controls and mitigations to management, technical teams and non-technical stakeholders.\n\nWhat you need to be successful:\n\nUniversity degree in Computer Science, AI/ML, Cybersecurity or related field, or equivalent experience.\n8-10 years of relevant experience, including in AI/ML models development and deployment. \nProficiency in programming languages such as Python, Java, or C++, and in AI/ML frameworks and libraries such as TensorFlow, PyTorch, scikit-learn, Keras, and XGBoost.\nStrong understanding of security concepts, including secure coding practices, threat modeling, and risk assessment.\nExpertise in securing AI/ML systems, including protection against adversarial attacks, data poisoning, ensuring the integrity of model training and inference processes, confidentiality of model and trained data.\nStrong analytical and problem-solving skills, attention to detail, and ability to work in a collaborative team environment.\nExcellent communication skills, including the ability to translate complex technical information for a non-technical audience.\n\nWhat we offer\n\nWe put you in control of career\n\nWe give you a competitive package\n\nWe help you perform at your best\n\nWe help you make a difference\n\nWe give you the freedom to be yourself\n\nWe give you the freedom to be yourself. We are creating an environment of unique individuals \u2013 like you \u2013 with different perspectives on the financial industry and the world. A diverse and inclusive environment in which everyone\u2019s voice counts and where you can reach your full potential.\n\nIf you believe you require a reasonable accommodation to participate in the job application or interview process, please contact us to request accommodation.\n\nDon\u2019t meet every single requirement? At Swift, we are dedicated to building a workplace where people can bring their full selves and ideas to the team, so if you are excited about this role, we encourage you to apply even if you do not meet every single qualification.\n\nSimilar Jobs (5)\nSecurity Architect\nlocations\n2 Locations\ntime type\nFull time\nposted on\nPosted 17 Days Ago\nPKI Security Architect\nlocations\n2 Locations\nposted on\nPosted Yesterday\nHybrid Platform Security Architect\nlocations\nManassas, United States\nposted on\nPosted 16 Days Ago\nView All 5 Jobs\nLoading\nFollow Us\n\u00a9 2025 Workday, Inc. All rights reserved.\n\nOutput:\nResponsibilities:\n- Design, develop, and implement security frameworks and strategies to protect AI/ML models and their use, and related data, applications and systems from adversarial attacks and other security threats.\n- Develop standards and best practices for a secure use, development, deployment, and operationalization of AI/ML (predictive AI, generative AI and Large Language Models).\n- Analyze potential security risks in AI/ML applications, such as model poisoning, data leakage, and other adversarial machine learning threats, and define mitigations that can be effectively implemented.\n- Collaborate with cross-functional teams to ensure AI/ML systems are integrated, deployed or leveraged with robust security practices throughout the development lifecycle of proprietary models, or through the implementation of pre-trained models, AI-based SaaS solutions, ...\n- Research and stay ahead of emerging security threats in AI/ML and propose innovative defense strategies.\n- Conduct security assessments and robustness testing of AI/ML models, with appropriate tooling, identifying weaknesses and providing recommendations for improvement.\n- Collaborate with internal teams to ensure compliance with relevant regulations, standards, and security frameworks in AI/ML-related initiatives.\n- Provide guidance and act as centre of expertise for business, technical, legal, privacy and risk teams on assessing risks and implementing controls for AI/ML projects.\n- Effectively communicate complex AI/ML security assessments, risks, controls and mitigations to management, technical teams and non-technical stakeholders.\n\nRequirements:\n- University degree in Computer Science, AI/ML, Cybersecurity or related field, or equivalent experience.\n- 8-10 years of relevant experience, including in AI/ML models development and deployment. \n- Proficiency in programming languages such as Python, Java, or C++, and in AI/ML frameworks and libraries such as TensorFlow, PyTorch, scikit-learn, Keras, and XGBoost.\n- Strong understanding of security concepts, including secure coding practices, threat modeling, and risk assessment.\n- Expertise in securing AI/ML systems, including protection against adversarial attacks, data poisoning, ensuring the integrity of model training and inference processes, confidentiality of model and trained data.\n- Strong analytical and problem-solving skills, attention to detail, and ability to work in a collaborative team environment.\n- Excellent communication skills, including the ability to translate complex technical information for a non-technical audience.",
    "compare": "Job Description:\n\nResponsibilities:\n- Design, develop, and implement security frameworks for AI/ML models.\n- Collaborate with cross-functional teams for AI/ML security.\n- Conduct security assessments for AI/ML systems.\n\nRequirements:\n- 8-10 years of experience in AI/ML.\n- Expertise in Python, TensorFlow, and security concepts for AI/ML systems.\n- Data Leakage\n- Master's or a University degree in Computer Science or related field, or equivalent experience.\n- PySpark\n- SQL\n- LLM\n\nCV:\n- Skills: Python, TensorFlow, Data Security, Threat Modeling, AI/ML, Pytorch, Scikit-Learn\n- Experience: AI/ML development, Security of AI/ML models, Threat modeling expertise, collaborative, Image Processing, Computer Vision, Vision Transformer, \n- Education: PhD in Artificial Intellgience\n\nOutput:\nThe Semantic Similarity Percentage: 72.5%\n\nSimilar keywords:\n- Python\n- Tensorflow\n- AI/ML\n- Security\n- collaboration\n- PhD\n\nDifferent keywords:\n- Data Leakage\n- SQL\n- PySpark\n- LLM\n\nThe Similarity percentage between the similar and different keywords: 66%"
}